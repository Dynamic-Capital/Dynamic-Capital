"""AwesomeAPI synchronisation orchestrator with multi-LLM summarisation."""

from __future__ import annotations

import json
import textwrap
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, Iterable, Mapping, MutableMapping, Optional, Sequence

from .awesome_api import (
    AwesomeAPIAutoCalculator,
    AwesomeAPIAutoMetrics,
    AwesomeAPIClient,
    AwesomeAPIError,
    DEFAULT_HISTORY,
)
from .data_pipeline import InstrumentMeta, MarketDataIngestionJob, RawBar
from .multi_llm import (
    LLMConfig,
    LLMRun,
    collect_strings,
    parse_json_response,
    serialise_runs,
)
from .trade_logic import MarketSnapshot

__all__ = [
    "AwesomeAlgoSyncEngine",
    "AwesomeAlgoSyncReport",
    "AwesomeAlgoSyncRequest",
    "AwesomeLLMInsights",
]


def _normalise_pairs(pairs: Iterable[str]) -> tuple[str, ...]:
    unique: MutableMapping[str, None] = {}
    for pair in pairs:
        if not pair:
            continue
        cleaned = pair.strip()
        if cleaned:
            unique.setdefault(cleaned, None)
    return tuple(unique.keys())


def _json_default(value: Any) -> Any:
    if isinstance(value, datetime):
        return value.isoformat()
    raise TypeError(f"Object of type {type(value).__name__} is not JSON serialisable")


@dataclass(slots=True)
class AwesomeLLMInsights:
    """Normalised insights distilled from multiple LLM responses."""

    summary: Optional[str]
    opportunities: list[str]
    risks: list[str]
    actions: list[str]
    highlights: list[str]
    alerts: list[str]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "summary": self.summary,
            "opportunities": list(self.opportunities),
            "risks": list(self.risks),
            "actions": list(self.actions),
            "highlights": list(self.highlights),
            "alerts": list(self.alerts),
        }


@dataclass(slots=True)
class AwesomeAlgoSyncRequest:
    """Input payload describing the synchronisation scope."""

    pairs: Sequence[str]
    instruments: Mapping[str, InstrumentMeta]
    history: int = DEFAULT_HISTORY
    metadata: Mapping[str, Any] = field(default_factory=dict)
    context: Mapping[str, Any] = field(default_factory=dict)
    notes: Sequence[str] = field(default_factory=tuple)
    llm_configs: Optional[Sequence[LLMConfig]] = None
    prompt_instructions: Optional[str] = None

    def __post_init__(self) -> None:
        self.pairs = _normalise_pairs(self.pairs)
        self.metadata = dict(self.metadata)
        self.context = dict(self.context)
        self.notes = tuple(
            note.strip() for note in self.notes if isinstance(note, str) and note.strip()
        )
        if self.history <= 1:
            raise ValueError("history must be at least 2 to compute AwesomeAPI metrics")

    def instrument_for(self, pair: str) -> Optional[InstrumentMeta]:
        return self.instruments.get(pair)


@dataclass(slots=True)
class AwesomeAlgoSyncReport:
    """Structured output generated by :class:`AwesomeAlgoSyncEngine`."""

    snapshots: Dict[str, MarketSnapshot]
    metrics: Dict[str, AwesomeAPIAutoMetrics]
    errors: Dict[str, str]
    prompt_payload: Dict[str, Any]
    prompt: str
    llm_runs: tuple[LLMRun, ...]
    llm_payloads: Dict[str, Dict[str, Any]]
    insights: Optional[AwesomeLLMInsights]

    @property
    def raw_llm_responses(self) -> Optional[str]:
        if not self.llm_runs:
            return None
        return serialise_runs(self.llm_runs)


@dataclass(slots=True)
class AwesomeAlgoSyncEngine:
    """Coordinate AwesomeAPI market ingestion with multi-LLM summarisation."""

    client: AwesomeAPIClient = field(default_factory=AwesomeAPIClient)
    job: MarketDataIngestionJob = field(default_factory=MarketDataIngestionJob)
    calculator: AwesomeAPIAutoCalculator = field(default_factory=AwesomeAPIAutoCalculator)
    llm_configs: Sequence[LLMConfig] = field(default_factory=tuple)
    history: int = DEFAULT_HISTORY
    llm_fallback_key: str = "summary"
    prompt_header: str = (
        "You are the Dynamic Capital synchronisation orchestrator. Analyse the fresh "
        "AwesomeAPI telemetry and craft JSON guidance for the trading desk."
    )

    def __post_init__(self) -> None:
        # Ensure the calculator reuses the orchestrator client for shared caching.
        if hasattr(self.calculator, "client"):
            self.calculator.client = self.client  # type: ignore[attr-defined]

    def sync(self, request: AwesomeAlgoSyncRequest) -> AwesomeAlgoSyncReport:
        history = request.history or self.history
        pair_payloads: Dict[str, Dict[str, Any]] = {}
        snapshots: Dict[str, MarketSnapshot] = {}
        metrics_map: Dict[str, AwesomeAPIAutoMetrics] = {}
        errors: Dict[str, str] = {}

        for pair in request.pairs:
            instrument = request.instrument_for(pair)
            if instrument is None:
                errors[pair] = "instrument metadata missing"
                continue

            try:
                bars = list(self.client.fetch_bars(pair, limit=history))
            except AwesomeAPIError as exc:
                errors[pair] = str(exc)
                continue

            if not bars:
                errors[pair] = "AwesomeAPI returned no bars"
                continue

            try:
                metrics = self.calculator.compute_metrics(pair, bars=bars)
            except (AwesomeAPIError, ValueError) as exc:
                errors[pair] = f"metrics: {exc}"
                continue

            try:
                snapshots_list = self.job.run(bars, instrument)
            except Exception as exc:  # pragma: no cover - defensive guard
                errors[pair] = f"snapshot: {exc}"
                continue

            if not snapshots_list:
                errors[pair] = "AwesomeAPI ingestion produced no snapshots"
                continue

            snapshot = snapshots_list[-1]
            snapshots[pair] = snapshot
            metrics_map[pair] = metrics
            pair_payloads[pair] = {
                "instrument": {
                    "symbol": instrument.symbol,
                    "pip_size": instrument.pip_size,
                    "pip_value": instrument.pip_value,
                },
                "snapshot": self._snapshot_payload(snapshot),
                "metrics": self._metrics_payload(metrics),
            }

        prompt_payload = self._build_prompt_payload(pair_payloads, request, errors)
        prompt = self._build_prompt(prompt_payload, request)

        configs = tuple(request.llm_configs or self.llm_configs)
        llm_runs: list[LLMRun] = []
        llm_payloads: Dict[str, Dict[str, Any]] = {}
        insights: Optional[AwesomeLLMInsights] = None

        if pair_payloads and configs:
            payload_iter: list[Dict[str, Any]] = []
            for config in configs:
                run = config.run(prompt)
                llm_runs.append(run)
                parsed = parse_json_response(run.response, fallback_key=self.llm_fallback_key) or {}
                llm_payloads[config.name] = dict(parsed)
                payload_iter.append(llm_payloads[config.name])
            insights = self._derive_insights(payload_iter)

        return AwesomeAlgoSyncReport(
            snapshots=snapshots,
            metrics=metrics_map,
            errors=errors,
            prompt_payload=prompt_payload,
            prompt=prompt,
            llm_runs=tuple(llm_runs),
            llm_payloads=llm_payloads,
            insights=insights,
        )

    def _build_prompt_payload(
        self,
        pairs: Mapping[str, Mapping[str, Any]],
        request: AwesomeAlgoSyncRequest,
        errors: Mapping[str, str],
    ) -> Dict[str, Any]:
        payload: Dict[str, Any] = {"pairs": dict(pairs)}
        if request.metadata:
            payload["metadata"] = dict(request.metadata)
        if request.context:
            payload["context"] = dict(request.context)
        if request.notes:
            payload["notes"] = list(request.notes)
        if errors:
            payload["errors"] = dict(errors)
        return payload

    def _build_prompt(self, payload: Mapping[str, Any], request: AwesomeAlgoSyncRequest) -> str:
        instructions = request.prompt_instructions or self.prompt_header
        payload_json = json.dumps(payload, indent=2, default=_json_default, sort_keys=True)
        return textwrap.dedent(
            f"""
            {instructions}

            Respond with a compact JSON object containing:
              - "summary": consolidated market stance.
              - "opportunities": array of notable upside setups.
              - "risks": array of material threats or downside catalysts.
              - "actions": array of recommended trade or risk adjustments.
              - "alerts": optional urgent warnings to surface to the desk.

            AwesomeAPI telemetry:
            {payload_json}
            """
        ).strip()

    def _snapshot_payload(self, snapshot: MarketSnapshot) -> Dict[str, Any]:
        return {
            "symbol": snapshot.symbol,
            "timestamp": snapshot.timestamp,
            "close": snapshot.close,
            "rsi_fast": snapshot.rsi_fast,
            "adx_fast": snapshot.adx_fast,
            "rsi_slow": snapshot.rsi_slow,
            "adx_slow": snapshot.adx_slow,
            "pip_size": snapshot.pip_size,
            "pip_value": snapshot.pip_value,
            "mechanical_state": snapshot.mechanical_state,
            "mechanical_bias": snapshot.mechanical_bias(),
            "seasonal_bias": snapshot.seasonal_bias,
            "seasonal_confidence": snapshot.seasonal_confidence,
        }

    def _metrics_payload(self, metrics: AwesomeAPIAutoMetrics) -> Dict[str, Any]:
        return {
            "sample_size": metrics.sample_size,
            "latest_close": metrics.latest_close,
            "previous_close": metrics.previous_close,
            "absolute_change": metrics.absolute_change,
            "percentage_change": metrics.percentage_change,
            "average_close": metrics.average_close,
            "high": metrics.high,
            "low": metrics.low,
            "price_range": metrics.price_range,
            "cumulative_return": metrics.cumulative_return,
            "average_daily_change": metrics.average_daily_change,
            "volatility": metrics.volatility,
            "trend_strength": metrics.trend_strength,
        }

    def _derive_insights(
        self, payloads: Sequence[Mapping[str, Any]]
    ) -> Optional[AwesomeLLMInsights]:
        if not payloads:
            return None

        summary: Optional[str] = None
        opportunity_sources: list[Any] = []
        risk_sources: list[Any] = []
        action_sources: list[Any] = []
        highlight_sources: list[Any] = []
        alert_sources: list[Any] = []

        for payload in payloads:
            if summary is None:
                for key in ("summary", "narrative", "analysis", "commentary"):
                    candidate = payload.get(key)
                    if candidate:
                        summary = str(candidate).strip()
                        if summary:
                            break

            opportunity_sources.extend(
                payload.get(key)
                for key in (
                    "opportunities",
                    "opportunity_highlights",
                    "upside",
                    "signals",
                )
            )
            risk_sources.extend(
                payload.get(key)
                for key in ("risks", "risk_notes", "concerns", "warnings")
            )
            action_sources.extend(
                payload.get(key)
                for key in (
                    "actions",
                    "recommended_actions",
                    "next_steps",
                    "playbook",
                )
            )
            highlight_sources.extend(
                payload.get(key)
                for key in ("highlights", "data_signals", "insights")
            )
            alert_sources.extend(payload.get(key) for key in ("alerts", "urgent_calls"))

        return AwesomeLLMInsights(
            summary=summary,
            opportunities=collect_strings(*opportunity_sources),
            risks=collect_strings(*risk_sources),
            actions=collect_strings(*action_sources),
            highlights=collect_strings(*highlight_sources),
            alerts=collect_strings(*alert_sources),
        )

