"""Market intelligence workflow that ensembles Grok-1 with DeepSeek-V3."""

from __future__ import annotations

import json
import math
import textwrap
from collections.abc import Mapping as MappingCollection, Sequence as SequenceCollection
from dataclasses import dataclass, field
from typing import Any, Dict, Mapping, Optional, Sequence, Tuple

from .grok_advisor import GrokAdvisor
from .multi_llm import CompletionClient, LLMConfig, collect_strings, parse_json_response, serialise_runs
from .trade_logic import ActivePosition, MarketSnapshot


@dataclass(slots=True)
class MarketIntelligenceRequest:
    """Input payload for generating a market intelligence report."""

    snapshot: MarketSnapshot
    context: Dict[str, Any] = field(default_factory=dict)
    strategy_context: Dict[str, Any] = field(default_factory=dict)
    macro_events: Sequence[str] = field(default_factory=tuple)
    watchlist: Sequence[str] = field(default_factory=tuple)
    open_positions: Sequence[ActivePosition] = field(default_factory=tuple)
    analytics: Dict[str, Any] = field(default_factory=dict)


@dataclass(slots=True)
class MarketIntelligenceReport:
    """Structured output generated by :class:`MarketIntelligenceEngine`."""

    narrative: str
    opportunities: list[str]
    risks: list[str]
    recommended_actions: list[str]
    confidence: Optional[float]
    alerts: list[str]
    metadata: Dict[str, Any]
    raw_response: Optional[str]


@dataclass(slots=True)
class MarketIntelligenceEngine:
    """Coordinates Grok-1 insights with DeepSeek-V3 risk arbitration."""

    grok_client: CompletionClient
    deepseek_client: CompletionClient
    grok_temperature: float = 0.2
    grok_nucleus_p: float = 0.9
    grok_max_tokens: int = 384
    deepseek_temperature: float = 0.15
    deepseek_nucleus_p: float = 0.9
    deepseek_max_tokens: int = 384
    max_macro_events: int = 6
    max_watchlist: int = 10
    max_positions: int = 6
    analytics_top_k: int = 10
    max_correlation_pairs: int = 8

    def generate_report(self, request: MarketIntelligenceRequest) -> MarketIntelligenceReport:
        """Return an aggregated intelligence brief for the supplied market state."""

        prompt_payload, prompt_meta = self._prepare_prompt_payload(request)

        grok_prompt = self._build_grok_prompt(prompt_payload, prompt_meta)
        grok_run = LLMConfig(
            name="grok-1",
            client=self.grok_client,
            temperature=self.grok_temperature,
            nucleus_p=self.grok_nucleus_p,
            max_tokens=self.grok_max_tokens,
        ).run(grok_prompt)
        grok_payload = parse_json_response(grok_run.response, fallback_key="narrative") or {}

        deepseek_prompt = self._build_deepseek_prompt(
            prompt_payload,
            grok_payload,
            prompt_meta,
        )
        deepseek_run = LLMConfig(
            name="deepseek-v3",
            client=self.deepseek_client,
            temperature=self.deepseek_temperature,
            nucleus_p=self.deepseek_nucleus_p,
            max_tokens=self.deepseek_max_tokens,
        ).run(deepseek_prompt)
        deepseek_payload = parse_json_response(deepseek_run.response, fallback_key="rationale") or {}

        alerts = collect_strings(
            grok_payload.get("alerts"),
            deepseek_payload.get("alerts"),
        )

        opportunities = collect_strings(
            grok_payload.get("opportunities"),
            grok_payload.get("opportunity_summary"),
        )
        risks = collect_strings(
            grok_payload.get("risks"),
            deepseek_payload.get("risks"),
            deepseek_payload.get("risk_notes"),
        )
        actions = collect_strings(
            grok_payload.get("actions"),
            grok_payload.get("strategy_actions"),
            deepseek_payload.get("recommended_actions"),
        )

        narrative = self._resolve_narrative(grok_payload, deepseek_payload)
        confidence = self._resolve_confidence(grok_payload, deepseek_payload)

        metadata: Dict[str, Any] = {
            "grok": grok_payload,
            "deepseek": deepseek_payload,
            "prompt_optimisation": prompt_meta,
        }

        raw_response = serialise_runs((grok_run, deepseek_run))

        return MarketIntelligenceReport(
            narrative=narrative,
            opportunities=opportunities,
            risks=risks,
            recommended_actions=actions,
            confidence=confidence,
            alerts=alerts,
            metadata=metadata,
            raw_response=raw_response,
        )

    def _build_grok_prompt(
        self,
        payload: Mapping[str, Any],
        prompt_meta: Mapping[str, Any],
    ) -> str:
        payload_json = json.dumps(payload, indent=2, default=str, sort_keys=True)
        optimisation_note = self._format_context_note(prompt_meta)

        return textwrap.dedent(
            f"""
            You are Grok-1 acting as the senior macro strategist for Dynamic Capital.
            Evaluate the market telemetry and think step-by-step about liquidity, momentum,
            and macro catalysts before responding. Return a single minified JSON object with:
              - "narrative": concise market story.
              - "opportunities": array of notable upside or relative value setups.
              - "risks": array of threats or cautionary dynamics.
              - "actions": array of recommended trading or hedging actions.
              - "confidence": optional number between 0 and 1 representing conviction.
              - "alerts": optional array of urgent callouts.
              - "data_signals": optional key metrics that influenced your reasoning.
            Do not include markdown or explanations outside the JSON payload.

            {optimisation_note}

            Market telemetry:
            {payload_json}
            """
        ).strip()

    def _build_deepseek_prompt(
        self,
        payload: Mapping[str, Any],
        grok_payload: Mapping[str, Any],
        prompt_meta: Mapping[str, Any],
    ) -> str:
        snapshot = payload.get("snapshot", {})
        snapshot_json = json.dumps(
            {
                "symbol": snapshot.get("symbol"),
                "timestamp": snapshot.get("timestamp"),
                "close": snapshot.get("close"),
                "pip_size": snapshot.get("pip_size"),
                "pip_value": snapshot.get("pip_value"),
            },
            indent=2,
            default=str,
            sort_keys=True,
        )
        grok_json = json.dumps(grok_payload, indent=2, default=str, sort_keys=True)
        events_json = json.dumps(
            payload.get("macro_events", []),
            indent=2,
            default=str,
        )
        analytics_json = json.dumps(
            payload.get("analytics", {}),
            indent=2,
            default=str,
            sort_keys=True,
        )
        strategy_context_json = json.dumps(
            payload.get("strategy_context", {}),
            indent=2,
            default=str,
            sort_keys=True,
        )
        optimisation_note = self._format_context_note(prompt_meta)

        return textwrap.dedent(
            f"""
            You are DeepSeek-V3 as Dynamic Capital's chief risk officer.
            Review the Grok-1 intelligence and audit it for blind spots. Work step-by-step
            through liquidity, regime stability, counterparty, and compliance risks before
            answering. Respond with a single minified JSON object containing:
              - "risk_score": optional value between 0 and 1 (higher means more risk).
              - "risks": optional array of identified risk narratives.
              - "alerts": optional array of immediate actions or warnings.
              - "recommended_actions": optional array of mitigations.
              - "confidence_modifier": optional multiplier for Grok confidence.
              - "adjusted_confidence": optional absolute confidence override.
              - "rationale": optional short explanation.
            Do not return any additional prose.

            {optimisation_note}

            Base snapshot:
            {snapshot_json}

            Grok-1 intelligence:
            {grok_json}

            Scheduled macro events:
            {events_json}

            Quantitative analytics:
            {analytics_json}

            Strategy context:
            {strategy_context_json}
            """
        ).strip()

    def _prepare_prompt_payload(
        self, request: MarketIntelligenceRequest
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        snapshot_payload, snapshot_meta = self._snapshot_payload(request.snapshot)
        context_payload, context_pruned_keys = self._compact_mapping(request.context)
        (
            strategy_context_payload,
            strategy_context_pruned_keys,
        ) = self._compact_mapping(request.strategy_context)
        macro_events, macro_omitted_items = self._normalise_sequence(
            request.macro_events,
            self.max_macro_events,
        )
        watchlist, watchlist_omitted_items = self._normalise_sequence(
            request.watchlist,
            self.max_watchlist,
        )
        positions_summary, positions_omitted = self._summarise_positions(
            request.open_positions
        )
        (
            analytics_summary,
            analytics_omitted_keys,
            analytics_pruned_keys,
        ) = self._prepare_analytics(
            request.analytics
        )

        payload: Dict[str, Any] = {"snapshot": snapshot_payload}
        if context_payload:
            payload["context"] = context_payload
        if strategy_context_payload:
            payload["strategy_context"] = strategy_context_payload
        if macro_events:
            payload["macro_events"] = macro_events
        if watchlist:
            payload["watchlist"] = watchlist
        if positions_summary:
            payload["open_positions"] = positions_summary
        if analytics_summary:
            payload["analytics"] = analytics_summary

        optimisation_meta: Dict[str, Any] = {
            "macro_events_retained": len(macro_events),
            "macro_events_omitted": len(macro_omitted_items),
            "macro_events_omitted_items": macro_omitted_items,
            "watchlist_retained": len(watchlist),
            "watchlist_omitted": len(watchlist_omitted_items),
            "watchlist_omitted_items": watchlist_omitted_items,
            "open_positions_retained": len(positions_summary),
            "open_positions_omitted": len(positions_omitted),
            "open_positions_omitted_details": positions_omitted,
            "analytics_retained": len(analytics_summary),
            "analytics_omitted": len(analytics_omitted_keys),
            "analytics_omitted_keys": analytics_omitted_keys,
            "analytics_pruned_keys": analytics_pruned_keys,
            "context_retained": len(context_payload),
            "context_pruned": len(context_pruned_keys),
            "context_pruned_keys": context_pruned_keys,
            "strategy_context_retained": len(strategy_context_payload),
            "strategy_context_pruned": len(strategy_context_pruned_keys),
            "strategy_context_pruned_keys": strategy_context_pruned_keys,
        }
        optimisation_meta.update(snapshot_meta)

        return payload, optimisation_meta

    def _snapshot_payload(
        self, snapshot: MarketSnapshot
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        payload: Dict[str, Any] = {
            "symbol": snapshot.symbol,
            "timestamp": snapshot.timestamp.isoformat(),
            "close": snapshot.close,
            "rsi_fast": snapshot.rsi_fast,
            "adx_fast": snapshot.adx_fast,
            "rsi_slow": snapshot.rsi_slow,
            "adx_slow": snapshot.adx_slow,
            "pip_size": snapshot.pip_size,
            "pip_value": snapshot.pip_value,
        }

        optional_fields = (
            "open",
            "high",
            "low",
            "daily_high",
            "daily_low",
            "previous_daily_high",
            "previous_daily_low",
            "weekly_high",
            "weekly_low",
            "previous_week_high",
            "previous_week_low",
            "seasonal_bias",
            "seasonal_confidence",
        )
        for field_name in optional_fields:
            value = getattr(snapshot, field_name, None)
            if value is not None:
                payload[field_name] = value

        snapshot_meta: Dict[str, Any] = {}
        if snapshot.correlation_scores:
            correlations = self._prioritise_metrics(
                snapshot.correlation_scores,
                self.max_correlation_pairs,
            )
            payload["correlation_scores"] = correlations
            snapshot_meta["snapshot_correlation_retained"] = len(correlations)
            snapshot_meta["snapshot_correlation_omitted"] = max(
                0,
                len(snapshot.correlation_scores) - len(correlations),
            )

        return payload, snapshot_meta

    def _summarise_positions(
        self, positions: Sequence[ActivePosition]
    ) -> Tuple[list[Dict[str, Any]], list[Dict[str, Any]]]:
        if not positions:
            return [], []

        def _position_snapshot(position: ActivePosition) -> Dict[str, Any]:
            snapshot: Dict[str, Any] = {
                "symbol": position.symbol,
                "direction": GrokAdvisor._direction(position.direction),
                "size": position.size,
                "entry_price": position.entry_price,
            }
            if position.stop_loss is not None:
                snapshot["stop_loss"] = position.stop_loss
            if position.take_profit is not None:
                snapshot["take_profit"] = position.take_profit
            if position.opened_at is not None:
                snapshot["opened_at"] = position.opened_at.isoformat()
            return snapshot

        if self.max_positions <= 0:
            return [], [_position_snapshot(position) for position in positions]

        summary = [_position_snapshot(position) for position in positions[: self.max_positions]]
        omitted_details = [_position_snapshot(position) for position in positions[self.max_positions :]]
        return summary, omitted_details

    def _prepare_analytics(
        self, analytics: Mapping[str, Any]
    ) -> Tuple[Dict[str, Any], list[str], list[str]]:
        compact, pruned_keys = self._compact_mapping(analytics)
        if not compact:
            return {}, [], pruned_keys

        if self.analytics_top_k <= 0:
            omitted_keys = list(compact.keys())
            return {}, omitted_keys, pruned_keys

        prioritised = self._prioritise_metrics(compact, self.analytics_top_k)
        omitted_keys = [key for key in compact.keys() if key not in prioritised]
        return prioritised, omitted_keys, pruned_keys

    @staticmethod
    def _compact_mapping(mapping: Mapping[str, Any]) -> Tuple[Dict[str, Any], list[str]]:
        compact: Dict[str, Any] = {}
        pruned_keys: list[str] = []
        for key, value in mapping.items():
            if value is None:
                pruned_keys.append(key)
                continue
            if isinstance(value, str):
                if not value.strip():
                    pruned_keys.append(key)
                    continue
            elif isinstance(value, MappingCollection):
                if not value:
                    pruned_keys.append(key)
                    continue
            elif isinstance(value, SequenceCollection) and not isinstance(value, (str, bytes)):
                if not list(value):
                    pruned_keys.append(key)
                    continue
            compact[key] = value
        return compact, pruned_keys

    def _normalise_sequence(
        self,
        values: Sequence[Any],
        limit: int,
    ) -> Tuple[list[str], list[str]]:
        cleaned: list[str] = []
        seen: set[str] = set()
        for value in values:
            text = str(value).strip()
            if not text or text in seen:
                continue
            seen.add(text)
            cleaned.append(text)

        if limit <= 0:
            return cleaned, []

        limited = cleaned[:limit]
        omitted_items = cleaned[limit:]
        return limited, omitted_items

    def _prioritise_metrics(
        self,
        analytics: Mapping[str, Any],
        limit: int,
    ) -> Dict[str, Any]:
        if limit <= 0:
            return {}

        items = list(analytics.items())
        if len(items) <= limit:
            return dict(items)

        numeric: list[Tuple[str, float]] = []
        fallback: list[Tuple[str, Any]] = []
        for key, value in items:
            number: Optional[float]
            try:
                number = float(value)
            except (TypeError, ValueError):
                number = None
            if number is None or not math.isfinite(number):
                fallback.append((key, value))
                continue
            numeric.append((key, number))

        numeric.sort(key=lambda item: abs(item[1]), reverse=True)

        prioritised: Dict[str, Any] = {}
        for key, number in numeric:
            if len(prioritised) >= limit:
                break
            prioritised[key] = number

        if len(prioritised) < limit:
            for key, value in fallback:
                if len(prioritised) >= limit:
                    break
                prioritised[key] = value

        if not prioritised:
            for key, value in items[:limit]:
                prioritised[key] = value

        return prioritised

    @staticmethod
    def _format_context_note(meta: Mapping[str, Any]) -> str:
        trimmed_segments = []
        labels = {
            "macro_events_omitted": "macro events",
            "watchlist_omitted": "watchlist instruments",
            "open_positions_omitted": "open positions",
            "analytics_omitted": "analytics signals",
        }
        for key, label in labels.items():
            omitted = meta.get(key)
            if isinstance(omitted, int) and omitted > 0:
                trimmed_segments.append(f"{omitted} {label}")
        if not trimmed_segments:
            return "All relevant context supplied; no truncation applied."
        joined = ", ".join(trimmed_segments)
        return f"Context trimmed to top signals; omitted {joined}."

    @staticmethod
    def _resolve_narrative(
        grok_payload: Mapping[str, Any],
        deepseek_payload: Mapping[str, Any],
    ) -> str:
        for key in ("narrative", "summary", "market_view", "rationale"):
            value = grok_payload.get(key)
            if isinstance(value, str) and value.strip():
                return value.strip()
        value = deepseek_payload.get("rationale")
        if isinstance(value, str) and value.strip():
            return value.strip()
        return "No narrative supplied."

    @staticmethod
    def _resolve_confidence(
        grok_payload: Mapping[str, Any],
        deepseek_payload: Mapping[str, Any],
    ) -> Optional[float]:
        absolute = MarketIntelligenceEngine._extract_float(
            deepseek_payload,
            ("adjusted_confidence", "final_confidence"),
        )
        if absolute is not None:
            return MarketIntelligenceEngine._clamp(absolute)

        grok_confidence = MarketIntelligenceEngine._extract_float(
            grok_payload,
            ("confidence", "adjusted_confidence", "conviction"),
        )
        modifier = MarketIntelligenceEngine._extract_float(
            deepseek_payload,
            ("confidence_modifier", "confidence_scale", "multiplier"),
        )
        if grok_confidence is None and modifier is None:
            return None
        if grok_confidence is None:
            return MarketIntelligenceEngine._clamp(modifier)
        if modifier is None:
            return MarketIntelligenceEngine._clamp(grok_confidence)
        return MarketIntelligenceEngine._clamp(grok_confidence * modifier)

    @staticmethod
    def _extract_float(payload: Mapping[str, Any], keys: Sequence[str]) -> Optional[float]:
        for key in keys:
            value = payload.get(key)
            if value is None:
                continue
            try:
                number = float(value)
            except (TypeError, ValueError):
                continue
            if not math.isfinite(number):
                continue
            return number
        return None

    @staticmethod
    def _clamp(value: float) -> float:
        return max(0.0, min(1.0, value))

__all__ = [
    "MarketIntelligenceEngine",
    "MarketIntelligenceReport",
    "MarketIntelligenceRequest",
]
