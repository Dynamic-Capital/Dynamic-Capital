# Dynamic Capital Monte Carlo Method Playbook

## Table of Contents

<!-- TOC:START -->
- [Core Concept & Origins](#core-concept--origins)
- [When to Use Monte Carlo](#when-to-use-monte-carlo)
- [General Algorithm](#general-algorithm)
  - [Pseudocode](#pseudocode)
- [Accuracy, Error, and Sample Size](#accuracy-error-and-sample-size)
- [Implementation Playbook](#implementation-playbook)
  - [1. Problem Setup](#1-problem-setup)
  - [2. Random Input Generation](#2-random-input-generation)
  - [3. Simulation Execution](#3-simulation-execution)
  - [4. Outcome Collection](#4-outcome-collection)
  - [5. Estimation & Reporting](#5-estimation--reporting)
- [Classic Scenarios](#classic-scenarios)
  - [Dice Probability](#dice-probability)
  - [Solitaire Win Rate](#solitaire-win-rate)
  - [Estimating \(\pi\)](#estimating-%CF%80)
  - [Option Pricing Sketch](#option-pricing-sketch)
- [Operational Patterns & Tips](#operational-patterns--tips)
- [Checklist](#checklist)
- [Glossary](#glossary)
<!-- TOC:END -->

## Core Concept & Origins
- The Monte Carlo method approximates complex analytical solutions by drawing repeated random samples from a model of the system.
- Stanislaw Ulam and John von Neumann popularized the method while evaluating neutron diffusion; Ulam initially explored it by replaying solitaire hands to empirically estimate win probabilities.
- Foundations:
  - **Randomness:** each trial is generated by a pseudo-random or quasi-random process.
  - **Law of Large Numbers:** the sample average of observations \(X_1, X_2, \ldots, X_N\) converges to the true expectation \(\mu = \mathbb{E}[X]\) as \(N\) increases.
  - **Central Limit Theorem:** sampling distributions approach normality, enabling confidence interval construction.

## When to Use Monte Carlo
Use simulation when analytical integration or enumeration is infeasible, but you can generate representative scenarios.

| Situation | Signal Monte Carlo Helps | Typical Output |
|-----------|--------------------------|----------------|
| High-dimensional integrals | Deterministic quadrature scales poorly with dimensions | Expected value estimate with confidence interval |
| Path-dependent payoffs | Payoff depends on full trajectory (options, logistics) | Distribution of payoffs or risk metrics |
| Rare events | Closed-form probabilities unavailable | Tail probability estimates via importance sampling |
| Complex constraints | Combinatorial rules difficult to express analytically | Feasibility probability, optimization heuristic |

## General Algorithm
1. **Define the problem** – translate the real-world question into a probabilistic model and identify the quantity of interest \(\mu = \mathbb{E}[f(X)]\).
2. **Sample inputs** – draw independent random samples \(X_i\) (or correlated samples via variance reduction techniques).
3. **Run simulations** – evaluate the function \(f(X_i)\) for \(i = 1, \ldots, N\).
4. **Aggregate outcomes** – compute statistics such as the mean, quantiles, or probability of success.
5. **Quantify error** – estimate variance, construct confidence intervals, and decide whether to increase \(N\).

The canonical estimator is the sample mean:
\[
\hat{\mu}_N = \frac{1}{N} \sum_{i=1}^N f(X_i)
\]
with estimated variance \(\widehat{\mathrm{Var}}(\hat{\mu}_N) = s^2/N\), where \(s^2\) is the sample variance of \(f(X_i)\).

### Pseudocode
```python
import random

N = 100_000
successes = 0

for _ in range(N):
    x = random_event()      # domain-specific random generator
    outcome = score(x)      # evaluate payoff or indicator
    successes += outcome

estimate = successes / N
stderr = (estimate * (1 - estimate) / N) ** 0.5
confidence = (estimate - 1.96 * stderr, estimate + 1.96 * stderr)
print({"estimate": estimate, "confidence_95": confidence})
```

## Accuracy, Error, and Sample Size
- **Standard error:** \(\mathrm{SE}(\hat{\mu}) = \sigma / \sqrt{N}\), where \(\sigma^2\) is the variance of \(f(X)\).
- **Confidence interval (95%):** \(\hat{\mu} \pm 1.96 \times \widehat{\mathrm{SE}}\).
- **Sample size planning:** to achieve margin of error \(\epsilon\), choose \(N \approx (1.96 \sigma / \epsilon)^2\).
- **Variance reduction:** antithetic variates, control variates, stratified sampling, and quasi-random (Sobol, Halton) sequences shrink \(\sigma\) without increasing \(N\).

| Target Relative Error | Approximate Trials Needed (variance scaled to 1) |
|-----------------------|-----------------------------------------------|
| 10%                   | 400                                           |
| 5%                    | 1,600                                         |
| 2%                    | 10,000                                        |
| 1%                    | 40,000                                        |

## Implementation Playbook
### 1. Problem Setup
- Define state variables, constraints, and payoff function \(f\).
- Clarify measurement unit (probability, expected value, Value-at-Risk).
- Establish stopping rules: maximum runtime, acceptable error, convergence diagnostics.

### 2. Random Input Generation
- Select high-quality pseudo-random generators or low-discrepancy sequences.
- Map uniform random numbers to domain variables (inverse transform, accept–reject, copulas for dependencies).
- Seed management: store seeds for reproducibility and scenario replay.

### 3. Simulation Execution
- Structure loops to support parallelization (vectorized libraries, GPU batching, distributed workers).
- Apply variance reduction when baseline variance is high.
- Track runtime metrics and log intermediate aggregates for monitoring.

### 4. Outcome Collection
- Persist raw results when downstream analytics require them; otherwise store sufficient statistics (sum, sum of squares, count).
- Segment results by scenario tags (market regime, policy option) for conditional analysis.
- Monitor convergence by plotting running averages and confidence intervals.

### 5. Estimation & Reporting
- Compute point estimates, variance, and confidence bounds.
- Report sensitivity to assumptions (input distributions, correlations).
- Communicate convergence status, runtime, and reproducibility info (seed, code version).

## Classic Scenarios
### Dice Probability
- **Objective:** probability that two fair dice sum to at least 10.
- **Model:** generate independent integers from 1–6; evaluate indicator \(\mathbf{1}\{x_1 + x_2 \geq 10\}\).
- **Output:** \(\hat{p} = \text{successes} / N\) with confidence interval from binomial standard error.

### Solitaire Win Rate
- **Objective:** estimate the probability of winning a specific solitaire variant.
- **Model:** encode shuffling rules, move heuristics, and end-state detection.
- **Output:** win probability, distribution over turns-to-win, and sensitivity to alternate strategies.

### Estimating \(\pi\)
- **Objective:** approximate \(\pi\) via geometry.
- **Model:** sample points \((u, v)\) uniformly in the unit square; count those satisfying \(u^2 + v^2 \leq 1\).
- **Estimator:** \(\pi \approx 4 \times \frac{\text{points inside circle}}{N}\).
- **Enhancement:** stratify samples by subdividing the square to reduce variance.

### Option Pricing Sketch
- **Objective:** price a European call option under geometric Brownian motion.
- **Model:** simulate terminal asset price \(S_T = S_0 \exp\left((r - \frac{1}{2}\sigma^2)T + \sigma \sqrt{T} Z\right)\) where \(Z \sim \mathcal{N}(0,1)\).
- **Estimator:** \(\hat{C} = e^{-rT} \frac{1}{N} \sum_{i=1}^N \max(S_T^{(i)} - K, 0)\).
- **Variance reduction:** use antithetic pairs \(Z\) and \(-Z\) to tighten intervals.

## Operational Patterns & Tips
- Start with a pilot run (1–5% of final \(N\)) to estimate variance, then scale \(N\) to hit precision targets.
- Automate convergence diagnostics: terminate when confidence interval width \(<\) tolerance for consecutive checkpoints.
- Leverage distributed compute (Ray, Dask, GPU kernels) when each trial is expensive.
- Document assumptions about correlations, distributions, and random seeds for auditability.
- For rare-event estimation, bias the sampling toward critical regions and weight samples appropriately (importance sampling).

## Checklist
- [ ] Problem modeled with clear payoff function and constraints.
- [ ] Random number generators seeded and documented.
- [ ] Variance assessed; variance reduction applied if beneficial.
- [ ] Confidence intervals computed and reviewed for convergence.
- [ ] Results archived with metadata (seed, version, runtime, inputs).
- [ ] Findings communicated with context (sensitivity, limitations, recommended next steps).

## Glossary
- **Antithetic Variates:** Paired samples with negative correlation to reduce variance.
- **Control Variate:** Known-expectation variable used to adjust estimates and decrease variance.
- **Importance Sampling:** Technique that samples from an alternative distribution and reweights observations to focus on rare events.
- **Quasi-Random Sequence:** Low-discrepancy sequence that systematically covers the sample space more uniformly than pure random draws.
- **Standard Error:** Estimated standard deviation of the sampling distribution of an estimator.
