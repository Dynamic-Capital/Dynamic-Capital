"""Predictive diffusion model for estimating narrative spread dynamics."""

from __future__ import annotations

from dataclasses import dataclass
from statistics import fmean
from typing import Iterable, Mapping, MutableSequence, Sequence

from .engine import DiffusionNode, DiffusionSignal

__all__ = [
    "DiffusionModelParameters",
    "DiffusionModelTrainingSample",
    "DiffusionNodeForecast",
    "DiffusionModelResult",
    "DynamicDiffusionModel",
]


def _clamp_unit(value: float) -> float:
    numeric = float(value)
    if numeric < 0.0:
        return 0.0
    if numeric > 1.0:
        return 1.0
    return numeric


def _normalise_nodes(
    nodes: Mapping[str, DiffusionNode] | Sequence[DiffusionNode]
) -> tuple[DiffusionNode, ...]:
    if isinstance(nodes, Mapping):
        values = nodes.values()
    else:
        values = nodes
    normalised: list[DiffusionNode] = []
    for node in values:
        if not isinstance(node, DiffusionNode):
            raise TypeError("nodes must be DiffusionNode instances")
        normalised.append(node)
    if not normalised:
        raise ValueError("at least one node must be supplied")
    return tuple(normalised)


@dataclass(slots=True)
class DiffusionModelParameters:
    """Weight configuration used by the diffusion model."""

    influence_weight: float = 0.35
    susceptibility_weight: float = 0.25
    retention_weight: float = 0.2
    novelty_weight: float = 0.15
    reinforcement_bias: float = 0.3
    volatility_penalty: float = 0.45

    def __post_init__(self) -> None:
        self.influence_weight = _clamp_unit(self.influence_weight)
        self.susceptibility_weight = _clamp_unit(self.susceptibility_weight)
        self.retention_weight = _clamp_unit(self.retention_weight)
        self.novelty_weight = _clamp_unit(self.novelty_weight)
        self.reinforcement_bias = _clamp_unit(self.reinforcement_bias)
        self.volatility_penalty = _clamp_unit(self.volatility_penalty)

    def as_mapping(self) -> Mapping[str, float]:
        return {
            "influence_weight": self.influence_weight,
            "susceptibility_weight": self.susceptibility_weight,
            "retention_weight": self.retention_weight,
            "novelty_weight": self.novelty_weight,
            "reinforcement_bias": self.reinforcement_bias,
            "volatility_penalty": self.volatility_penalty,
        }


@dataclass(slots=True)
class DiffusionModelTrainingSample:
    """Observed activation for calibrating the diffusion model."""

    node: DiffusionNode
    signal: DiffusionSignal
    observed_activation: float
    observed_volatility: float = 0.0

    def __post_init__(self) -> None:
        if not isinstance(self.node, DiffusionNode):
            raise TypeError("node must be a DiffusionNode")
        if not isinstance(self.signal, DiffusionSignal):
            raise TypeError("signal must be a DiffusionSignal")
        self.observed_activation = _clamp_unit(self.observed_activation)
        self.observed_volatility = _clamp_unit(self.observed_volatility)


@dataclass(slots=True)
class DiffusionNodeForecast:
    """Per-node activation forecast generated by the diffusion model."""

    node_name: str
    activation: float
    volatility: float
    influence_score: float
    confidence: float


@dataclass(slots=True)
class DiffusionModelResult:
    """Aggregate forecast for a network diffusion scenario."""

    signal: DiffusionSignal
    activation_potential: float
    spread_potential: float
    stability_index: float
    node_forecasts: tuple[DiffusionNodeForecast, ...]
    insights: tuple[str, ...]
    recommendations: tuple[str, ...]


class DynamicDiffusionModel:
    """Heuristic diffusion model providing forecast and calibration utilities."""

    def __init__(
        self,
        parameters: DiffusionModelParameters | Mapping[str, float] | None = None,
    ) -> None:
        if parameters is None:
            self._parameters = DiffusionModelParameters()
        elif isinstance(parameters, DiffusionModelParameters):
            self._parameters = parameters
        else:
            self._parameters = DiffusionModelParameters(**parameters)
        self._history: list[DiffusionModelResult] = []
        self._activation_bias = 0.0
        self._volatility_bias = 0.0

    @property
    def parameters(self) -> DiffusionModelParameters:
        return self._parameters

    @property
    def history(self) -> tuple[DiffusionModelResult, ...]:
        return tuple(self._history)

    def calibrate(self, samples: Iterable[DiffusionModelTrainingSample]) -> None:
        activations: MutableSequence[float] = []
        volatilities: MutableSequence[float] = []
        for sample in samples:
            prediction = self._score_node(sample.node, sample.signal)
            activations.append(sample.observed_activation - prediction)
            volatilities.append(
                sample.observed_volatility - self._estimate_volatility(sample.node)
            )
        if activations:
            self._activation_bias = max(-0.5, min(0.5, fmean(activations)))
        if volatilities:
            self._volatility_bias = max(-0.5, min(0.5, fmean(volatilities)))

    def forecast(
        self,
        nodes: Mapping[str, DiffusionNode] | Sequence[DiffusionNode],
        signal: DiffusionSignal,
        *,
        horizon: int = 3,
    ) -> DiffusionModelResult:
        if horizon <= 0:
            raise ValueError("horizon must be positive")
        network = _normalise_nodes(nodes)
        node_forecasts: list[DiffusionNodeForecast] = []
        for node in network:
            activation = self._project_activation(node, signal, horizon)
            volatility = self._project_volatility(node)
            node_forecasts.append(
                DiffusionNodeForecast(
                    node_name=node.name,
                    activation=activation,
                    volatility=volatility,
                    influence_score=_clamp_unit(
                        node.influence * self._parameters.influence_weight
                    ),
                    confidence=_clamp_unit(1.0 - abs(volatility - self._volatility_bias)),
                )
            )
        activation_values = [forecast.activation for forecast in node_forecasts]
        spread_values = [self._spread_component(node) for node in network]
        stability_values = [forecast.volatility for forecast in node_forecasts]
        activation_potential = (
            _clamp_unit(fmean(activation_values)) if activation_values else 0.0
        )
        spread_component = fmean(spread_values) if spread_values else 0.0
        spread_potential = _clamp_unit(0.6 * activation_potential + 0.4 * spread_component)
        stability_index = _clamp_unit(
            1.0 - (fmean(stability_values) if stability_values else 0.0)
        )
        insights = self._build_insights(
            activation_potential, spread_potential, stability_index
        )
        recommendations = self._build_recommendations(
            activation_potential, spread_potential, stability_index, signal
        )
        ordered_forecasts = tuple(
            sorted(node_forecasts, key=lambda forecast: forecast.activation, reverse=True)
        )
        result = DiffusionModelResult(
            signal=signal,
            activation_potential=round(activation_potential, 4),
            spread_potential=round(spread_potential, 4),
            stability_index=round(stability_index, 4),
            node_forecasts=ordered_forecasts,
            insights=insights,
            recommendations=recommendations,
        )
        self._history.append(result)
        return result

    def _score_node(self, node: DiffusionNode, signal: DiffusionSignal) -> float:
        weights = self._parameters
        total_weight = (
            weights.influence_weight
            + weights.susceptibility_weight
            + weights.retention_weight
            + weights.novelty_weight
        )
        if total_weight <= 0:
            return 0.0
        weighted_sum = (
            node.influence * weights.influence_weight
            + node.susceptibility * signal.coherence * weights.susceptibility_weight
            + node.retention * weights.retention_weight
            + signal.novelty * weights.novelty_weight
        )
        baseline = weighted_sum / total_weight
        return _clamp_unit(baseline + self._activation_bias)

    def _project_activation(
        self, node: DiffusionNode, signal: DiffusionSignal, horizon: int
    ) -> float:
        reinforcement = 1.0 + self._parameters.reinforcement_bias * min(horizon, 5) / 5.0
        activation = self._score_node(node, signal) * reinforcement
        return _clamp_unit(activation)

    def _estimate_volatility(self, node: DiffusionNode) -> float:
        volatility = (1.0 - node.retention) * self._parameters.volatility_penalty
        return _clamp_unit(volatility + self._volatility_bias)

    def _project_volatility(self, node: DiffusionNode) -> float:
        return self._estimate_volatility(node)

    def _spread_component(self, node: DiffusionNode) -> float:
        if not node.connections:
            return 0.1
        average_weight = fmean(float(weight) for weight in node.connections.values())
        connectivity = _clamp_unit(len(node.connections) / 5.0)
        return _clamp_unit(0.7 * average_weight + 0.3 * connectivity)

    def _build_insights(
        self, activation: float, spread: float, stability: float
    ) -> tuple[str, ...]:
        insights: list[str] = []
        if activation >= 0.7:
            insights.append("Network primed for strong narrative activation")
        elif activation <= 0.3:
            insights.append(
                "Activation potential limited; consider amplification catalysts"
            )
        if spread >= 0.65:
            insights.append("High propagation pathways available across the network")
        if stability <= 0.4:
            insights.append(
                "Propagation volatility elevated; retention buffers recommended"
            )
        if not insights:
            insights.append("Diffusion environment balanced with moderate opportunity")
        return tuple(insights)

    def _build_recommendations(
        self,
        activation: float,
        spread: float,
        stability: float,
        signal: DiffusionSignal,
    ) -> tuple[str, ...]:
        recommendations: list[str] = []
        if activation >= 0.75:
            recommendations.append("Launch reinforcement narrative sequencing")
        if spread >= 0.7:
            recommendations.append("Deploy cross-coalition amplification nodes")
        if stability <= 0.45:
            recommendations.append("Introduce stabilisation content to reduce volatility")
        if signal.novelty >= 0.6 and activation >= 0.55:
            recommendations.append(
                f"Capture momentum around {signal.origin} before novelty decays"
            )
        if not recommendations:
            recommendations.append("Monitor diffusion metrics; no immediate action required")
        seen: set[str] = set()
        ordered: list[str] = []
        for item in recommendations:
            if item not in seen:
                seen.add(item)
                ordered.append(item)
        return tuple(ordered)
